{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path_name=\"C:\\\\Users\\\\Home\\\\CIP_Lab Related Works\\\\DataSet1\\\\Amazon_Product.csv\"\n",
    "df=pd.read_csv(path_name,encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"Rating\"] , inplace = True)\n",
    "df[\"Rating\"] = df[\"Rating\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(413840, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=5, test_size=0.2)\n",
    "for train_index, test_index in split.split(df, df[\"Rating\"]): \n",
    "    strat_train = df.reindex(train_index)\n",
    "    strat_test = df.reindex(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331072 82768\n"
     ]
    }
   ],
   "source": [
    "X_train = strat_train[\"Reviews\"]\n",
    "#X_train_targetSentiment = strat_train[\"reviews.rating\"].astype(int)\n",
    "X_test = strat_test[\"Reviews\"]\n",
    "#X_test_targetSentiment = strat_test[\"reviews.rating\"].astype(int)\n",
    "print(len(X_train), len(X_test))\n",
    "#print(len(X_train_targetSentiment), len(X_test_targetSentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From E:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From E:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From E:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From E:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From E:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    " from tensorflow import keras\n",
    "model = keras.models.load_model('./Amazon_Final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data_majority = df[df['Rating'] <=3]\n",
    "data_minority = df[df['Rating'] >=4]\n",
    "\n",
    "bias = data_minority.shape[0]/data_majority.shape[0]\n",
    "# lets split train/test data first then \n",
    "train = pd.concat([data_majority.sample(frac=0.6,random_state=200),\n",
    "         data_minority.sample(frac=0.6,random_state=200)])\n",
    "test = pd.concat([data_majority.drop(data_majority.sample(frac=0.6,random_state=200).index),\n",
    "        data_minority.drop(data_minority.sample(frac=0.6,random_state=200).index)])\n",
    "\n",
    "train = shuffle(train)\n",
    "test = shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive data in training: 170998\n",
      "negative data in training: 77306\n",
      "positive data in test: 113999\n",
      "negative data in test: 51537\n"
     ]
    }
   ],
   "source": [
    "print('positive data in training:',(train['Rating'] >=4).sum())\n",
    "print('negative data in training:',(train['Rating'] <=3).sum())\n",
    "print('positive data in test:',(test['Rating'] >=4).sum())\n",
    "print('negative data in test:',(test['Rating'] <=3).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 1 2 3]\n",
      "majority class before upsample: (170998, 6)\n",
      "minority class before upsample: (77306, 6)\n",
      "After upsampling\n",
      "5    134017\n",
      "1     96003\n",
      "3     42471\n",
      "4     36981\n",
      "2     32524\n",
      "Name: Rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Rating'].unique())\n",
    "data_majority = train[train['Rating'] >=4]\n",
    "data_minority = train[train['Rating'] <=3]\n",
    "\n",
    "print(\"majority class before upsample:\",data_majority.shape)\n",
    "print(\"minority class before upsample:\",data_minority.shape)\n",
    "from sklearn.utils import resample\n",
    "# Upsample minority class\n",
    "data_minority_upsampled = resample(data_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples= data_majority.shape[0],    # to match majority class\n",
    "                                 random_state=42) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data_upsampled = pd.concat([data_majority, data_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "print(\"After upsampling\\n\",data_upsampled['Rating'].value_counts(),sep = \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (341996, 29)\n",
      "x_test shape (165536, 29)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(df['Reviews'].astype(str).values) # training with whole data\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(data_upsampled['Reviews'].astype(str).values)\n",
    "X_train = pad_sequences(X_train,maxlen=29)\n",
    "Y_train = pd.get_dummies(data_upsampled['Rating']).astype(str).values\n",
    "print('x_train shape:',X_train.shape)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(test['Reviews'].astype(str).values)\n",
    "X_test = pad_sequences(X_test,maxlen=29)\n",
    "Y_test = pd.get_dummies(test['Rating']).values\n",
    "print(\"x_test shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix [[ 7385  2557  2007  2767 14279]\n",
      " [ 2510   873   842  1107  4676]\n",
      " [ 2624  1024   982  1424  6480]\n",
      " [ 4931  1723  1535  2495 13727]\n",
      " [18944  5120  4239  7050 54235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.25      0.23     28995\n",
      "           1       0.08      0.09      0.08     10008\n",
      "           2       0.10      0.08      0.09     12534\n",
      "           3       0.17      0.10      0.13     24411\n",
      "           4       0.58      0.61      0.59     89588\n",
      "\n",
      "    accuracy                           0.40    165536\n",
      "   macro avg       0.23      0.23      0.22    165536\n",
      "weighted avg       0.39      0.40      0.39    165536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "batch_size = 128\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "Y_pred = model.predict_classes(X_test,batch_size = batch_size)\n",
    "df_test = pd.DataFrame({'true': Y_test.tolist(), 'pred':Y_pred})\n",
    "df_test['true'] = df_test['true'].apply(lambda x: np.argmax(x))\n",
    "print(\"confusion matrix\",confusion_matrix(df_test.true, df_test.pred))\n",
    "print(classification_report(df_test.true, df_test.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s\n",
      "[9.9551618e-01 4.1723251e-07 2.7716160e-06 3.5762787e-06 5.6379715e-08]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(df['Reviews'].astype(str).values)\n",
    "twt = [\"Product is  damaged\"]\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twt = pad_sequences(twt, maxlen=29, dtype='int32', value=0)\n",
    "#print(twt)\n",
    "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "i = np.argmax(sentiment)\n",
    "print(np.argmax(sentiment))\n",
    "if i<=1:\n",
    "        flag=\"Negative\"\n",
    "        print(\"Negative\")\n",
    "if i==2:\n",
    "        flag=\"Neutral\"\n",
    "        print(\"Neural\")\n",
    "if(i>=3):\n",
    "        flag=\"Positive\"\n",
    "        print(\"Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s\n",
      "[7.7784061e-06 2.6154518e-04 5.5521727e-05 5.4647368e-01 7.0978171e-04]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(df['Reviews'].astype(str).values)\n",
    "twt = [\"package superb\"]\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twt = pad_sequences(twt, maxlen=29, dtype='int32', value=0)\n",
    "#print(twt)\n",
    "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "i = np.argmax(sentiment)\n",
    "print(np.argmax(sentiment))\n",
    "if i<=1:\n",
    "        flag=\"Negative\"\n",
    "        print(\"Negative\")\n",
    "if i==2:\n",
    "        flag=\"Neutral\"\n",
    "        print(\"Neural\")\n",
    "if(i>=3):\n",
    "        flag=\"Positive\"\n",
    "        print(\"Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request\n",
    "global model1\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import h5py\n",
    "app = Flask(__name__,static_folder='C:\\\\Users\\\\Home\\\\Amazon Sentiment Analysis\\\\static')\n",
    "@app.route('/')\n",
    "def index_view():\n",
    "    return render_template('temp.html')\n",
    "\n",
    "def get_model():\n",
    "    global model1\n",
    "    #model = Sequential()\n",
    "        # this is key : save the graph after loading the model\n",
    "    global graph\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "\n",
    "# Initialization\n",
    "\n",
    "    model1 = keras.models.load_model('./Amazon_Final.h5')\n",
    "    #model=load_model(\"AmazonReview.h5\")\n",
    "    print(\" * Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# max_fatures = 2000\n",
    "# tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "# tokenizer.fit_on_texts(df['Reviews'].astype(str).values)\n",
    "# twt = [\"Product is good but package damaged\"]\n",
    "# #vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "# twt = tokenizer.texts_to_sequences(twt)\n",
    "# #padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "# twt = pad_sequences(twt, maxlen=29, dtype='int32', value=0)\n",
    "# #print(twt)\n",
    "# sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
    "# print(sentiment)\n",
    "\n",
    "\n",
    "# @app.route('/predict',methods=['GET','POST'])\n",
    "@app.route('/', methods=['GET','POST'])\n",
    "def predict(): \n",
    "    text1 = request.form['text1']\n",
    "    max_fatures = 2000\n",
    "    #tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "    #text_final = ''.join(c for c in text1 if not c.isdigit())\n",
    "    #tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "    #tokenizer.fit_on_texts(df['Reviews'].astype(str).values)\n",
    "    twt1 = text1\n",
    "    #vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "    twt1 = tokenizer.texts_to_sequences(twt1)\n",
    "    #padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "    twt1 = pad_sequences(twt1, maxlen=29, dtype='int32', value=0)\n",
    "    sentiment = model1.predict(twt1,batch_size=1,verbose = 2)[0]\n",
    "    print(sentiment)\n",
    "    i = np.argmax(sentiment)\n",
    "    print(np.argmax(sentiment))\n",
    "    if i<=1:\n",
    "        flag=\"Negative\"\n",
    "        print(\"Negative\")\n",
    "    if i==2:\n",
    "        flag=\"Neutral\"\n",
    "        print(\"Neural\")\n",
    "    if(i>=3):\n",
    "        flag=\"Positive\"\n",
    "        print(\"Positive\")\n",
    "    return render_template('index.html',name=\"User\",positive=(sentiment[3]+sentiment[4]),neutral=sentiment[2],negative=(sentiment[0]+sentiment[1]))\n",
    "    #return render_template('temp.html', final=sentiment[3]+sentiment[4], text1=text1,text2=sentiment[3]+sentiment[4],text3=sentiment[2],text5=sentiment[0]+sentiment[1],text4=flag)\n",
    "# @app.route('/', methods=['POST'])\n",
    "# def predict1(): \n",
    "#     text1 = request.form['text1']\n",
    "#     #text_final = ''.join(c for c in text1 if not c.isdigit())\n",
    "#     twt = text1\n",
    "#     #vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "#     twt = tokenizer.texts_to_sequences(twt)\n",
    "#     #padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "#     twt = pad_sequences(twt, maxlen=29, dtype='int32', value=0)\n",
    "#     print(twt)\n",
    "#     sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
    "#     print(sentiment)\n",
    "#     return render_template('temp.html', final=max(sentiment), text1=text1,text2=sentiment[2],text5=sentiment[0],text4=max(sentiment),text3=sentiment[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Model loaded!\n"
     ]
    }
   ],
   "source": [
    "get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [26/May/2021 16:49:14] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2021 16:49:15] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [26/May/2021 16:49:20] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:49:35] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.8114440e-03 2.9519200e-04 1.0842383e-03 8.6150169e-03 9.6922934e-01]\n",
      "4\n",
      "Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:49:35] \"\u001b[36mGET /static/neu.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [26/May/2021 16:49:35] \"\u001b[36mGET /static/pos.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [26/May/2021 16:49:35] \"\u001b[36mGET /static/amazon.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [26/May/2021 16:49:35] \"\u001b[36mGET /static/neg.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [26/May/2021 16:49:39] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:49:44] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04518726 0.01579249 0.00363177 0.07539967 0.35037085]\n",
      "4\n",
      "Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:49:51] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [26/May/2021 16:49:51] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:49:55] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.2850456e-05 4.4900179e-03 5.5620074e-04 1.8278262e-01 9.8116517e-01]\n",
      "4\n",
      "Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:49:59] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:50:15] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1539459e-04 5.5772662e-03 2.8154939e-02 2.6673079e-05 5.8127065e-05]\n",
      "2\n",
      "Neural\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:50:44] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:50:54] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.6187639e-04 1.3802022e-02 7.1569085e-03 4.5844823e-02 8.5041118e-01]\n",
      "4\n",
      "Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:50:57] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:51:01] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4680624e-04 4.7683716e-06 1.4603138e-06 2.8332174e-03 9.9108326e-01]\n",
      "4\n",
      "Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:51:14] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:51:34] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0626488e-01 1.9878149e-05 1.8650293e-04 9.0515614e-04 1.2553565e-01]\n",
      "0\n",
      "Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:51:44] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:52:14] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.7985315e-02 5.9273839e-04 5.8679283e-03 1.7060727e-02 8.3987725e-01]\n",
      "4\n",
      "Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:52:54] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:53:31] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04518726 0.01579249 0.00363177 0.07539967 0.35037085]\n",
      "4\n",
      "Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:54:04] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 - 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:54:15] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.2558582e-01 8.7320805e-05 1.9669533e-06 1.0392070e-04 1.1725811e-05]\n",
      "0\n",
      "Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:54:30] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:54:54] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.2558582e-01 8.7320805e-05 1.9669533e-06 1.0392070e-04 1.1725811e-05]\n",
      "0\n",
      "Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:55:44] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:56:05] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.8114440e-03 2.9519200e-04 1.0842383e-03 8.6150169e-03 9.6922934e-01]\n",
      "4\n",
      "Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:56:07] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:56:25] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08489901 0.00644559 0.01804581 0.03143841 0.4223505 ]\n",
      "4\n",
      "Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:56:55] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:57:05] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.2558582e-01 8.7320805e-05 1.9669533e-06 1.0392070e-04 1.1725811e-05]\n",
      "0\n",
      "Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2021 16:57:15] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(threaded=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('./Amazon_Final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(df['Reviews'].astype(str).values)\n",
    "twt = [\"Product is  good\"]\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twt = pad_sequences(twt, maxlen=29, dtype='int32', value=0)\n",
    "#print(twt)\n",
    "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "i = np.argmax(sentiment)\n",
    "print(np.argmax(sentiment))\n",
    "if i<=1:\n",
    "        flag=\"Negative\"\n",
    "        print(\"Negative\")\n",
    "if i==2:\n",
    "        flag=\"Neutral\"\n",
    "        print(\"Neural\")\n",
    "if(i>=3):\n",
    "        flag=\"Positive\"\n",
    "        print(\"Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
